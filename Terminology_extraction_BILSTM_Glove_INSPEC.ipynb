{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminology_extraction_BILSTM_Glove_INSPEC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "O4sY3EwBApRT",
        "2gP4atTi_N4w",
        "GI7zGCBa_ZD3",
        "ocBD0rW0A6Is",
        "nc0OCc0Kze_I"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvNtiiwcBGbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b391a658-7189-43b9-f7d0-ffa531f7baff"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers, metrics, utils, models\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, LSTM, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import codecs\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "from sklearn.utils import class_weight \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import OrderedDict\n",
        "from numpy.random import seed\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_jq6RHfvFwY",
        "colab_type": "text"
      },
      "source": [
        "Para reducir la aleatoriedad de los experimentos (cada evaluación de la ejecución del modelo). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89h0mh88t1r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed(421)\n",
        "tf.random.set_seed(123451)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pzfCiTwGW19",
        "colab_type": "text"
      },
      "source": [
        "Parámetros que se van a emplear.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugE-GKZV2FW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cambiar en función de lo que se quiera ejecutar\n",
        "new_model = True           # Entrena un nuevo modelo\n",
        "save_term_test = False     # Para guardar la terminología obtenida sobre el conjunto de test\n",
        "improved_model = True      # Modelo mejorado (red neuronal más profunda)\n",
        "predict = False            # Usa el modelo para predecir terminología de un corpus\n",
        "only_predict = False       # Usar un modelo guardado para predecir sobre un corpus "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQRtgJFpMeX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definir nombre de las rutas\n",
        "DATASET_PATH = '/content/drive/My Drive/TFM/Datasets/INSPEC'      # CAMBIAR AL QUE SALGA AL DESCARGAR DE GIT\n",
        "MODEL_PATH = '/content/drive/My Drive/TFM/ModelosCreados/Glove - BiLSTM (INSPEC)/m1_BiLSTM_glove'  # RUTA DONDE GUARDAR LOS MODELOS ENTRENADOS\n",
        "\n",
        "if save_term_test:\n",
        "    TERM_PATH_INSPEC = '/content/drive/My Drive/TFM/Terminología/Glove - BiLSTM (INSPEC)/m2_terminology_INSPEC.csv' # RUTA DONDE GUARDAR LA TERMINOLOGÍA GENERADA\n",
        "    \n",
        "if predict:\n",
        "    CORPUS_PATH = '/content/drive/My Drive/TFM/Corpus/Corpus_COVID/corpus_covid.pickle'     # RUTA CON EL CORPUS DE PREDICCIÓN\n",
        "    TERM_PATH_CORPUS = '/content/drive/My Drive/TFM/Terminología/Glove - BiLSTM (INSPEC)/m2_terminology_COVID.csv'\n",
        "    VOCABULARY_PATH = '/content/drive/My Drive/TFM/Embeddings/Glove/vocabulary_trained.pickle'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRUP4eZT8oXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_SIZE = 550      # máximo tamaño de los docmentos\n",
        "MAX_VOCABULARY_SIZE = 20000  # máxima cantidad de palabras del vocabulario               \n",
        "EMBEDDINGS_SIZE = 300        # tamaño de los word embeddings\n",
        "BATCH_SIZE = 32              # tamaño de los batchs de entrenamiento\n",
        "EPOCHS = 30                  # nº de épocas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOg7Brl_H9D",
        "colab_type": "text"
      },
      "source": [
        "# Clases y funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4sY3EwBApRT",
        "colab_type": "text"
      },
      "source": [
        "## **Funciones generales y de pre-proceso**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBh5BLtuH2Hq",
        "colab_type": "text"
      },
      "source": [
        "Función para obtener los documentos del Dataset estructurados. Los guarda en un diccionario donde la clave es el nombre de cada documento y el valor el contenido de cada documento.\n",
        "\n",
        "Entrada: ruta con los documentos del dataset.\n",
        "Salidas: \n",
        "* input_doc: diccionario con el nombre de los documentos como clave, el texto como valor. Serán las entradas del modelo, tras ser preprocesadas.\n",
        "* output_term: diccionario con el nombre de los documentos como clave, la terminología como valor. Será la salida del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYrhZboTF-rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path):\n",
        "\n",
        "        input_doc = {}    # diccionario que contendrá el nombre de los documentos como clave y su contenido como valor\n",
        "        output_term = {}  # diccionario que contendrá la terminología que se quiere extraer en los documentos\n",
        "        \n",
        "        for doc in os.listdir(path):\n",
        "            doc_file = path + '/' + str(doc)\n",
        "            if doc.endswith(\".abstr\"):                   # los documentos enteros son aquellos que acaban en .abstr\n",
        "                text = codecs.open(doc_file, \"r\", encoding='utf-8', errors='ignore').read()\n",
        "                input_doc[doc[:doc.find('.')]] = text    # la clave será el nombre del documento sin la extensión (hasta el .)\n",
        "            elif doc.endswith(\".uncontr\"):               # la terminología está contenida en los archivos .uncontr (no controlada) o .contr (controlada)\n",
        "              text = open(doc_file, \"rt\").read() \n",
        "              terms = text.split(';')\n",
        "              doc_name = doc[:doc.find('.')]\n",
        "              for term in terms:\n",
        "                  term = term.strip()\n",
        "                  if doc_name not in output_term:\n",
        "                      output_term[doc_name] = [term]\n",
        "                  else:\n",
        "                      output_term[doc_name].append(term)\n",
        "          \n",
        "        return input_doc, output_term"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ois5Lvl3P2s-",
        "colab_type": "text"
      },
      "source": [
        "Clase para construir un vocabulario que pueda emplearse en una capa tipo \"Embedding layer\" con word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maw6CUQSQE7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "\n",
        "    def __init__(self, voc_length = None):\n",
        "\n",
        "        self.word_freq = OrderedDict()   # diccionario que recuerda el orden de inserción de las palabras. Devuelve 1º las claves que se añadieron 1º. Clave: palabra. Valor: nº de veces que aparece.\n",
        "        self.word_index = {}             # diccionario normal\n",
        "        self.voc_length = voc_length     # para limitar el tamaño que queremos observar del diccionario\n",
        "\n",
        "    def new_vocabulary(self, tokenized_docs):  # función para obtener el diccionario de unos documentos pasados como parámetro tokenizados\n",
        "\n",
        "        for doc in tokenized_docs:\n",
        "            for tok in doc:                    # contador de tokens\n",
        "                if tok in self.word_freq:\n",
        "                    self.word_freq[tok] += 1   # si la palabra ya estaba en el diccionario, se incrementa el contador\n",
        "                else:\n",
        "                    self.word_freq[tok] = 1    # si no esta, se inicializa (es la priemra vez que aparece la palabra)\n",
        "\n",
        "        word_freq_ls = list(self.word_freq.items())              # convierte el diccionario en lista\n",
        "        word_freq_ls.sort(key = lambda x: x[1], reverse = True)  # ordena la lista, en primer lugar las palabras que aparecen más frecuentemente\n",
        "        sorted_voc = [word[0] for word in word_freq_ls]          # lista que contiene las claves (palabras) ordenadas, pero sin los valores\n",
        "                                                                 # el índice 0 nunca se asigna a una palabra\n",
        "        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1))))) # nuevo diccionario donde aparecen las palabras (claves) ordenadas y el valor es ascendente (la palabra más frecuente tiene valor 1, la 2º el 2...)\n",
        "\n",
        "\n",
        "    def texts_to_word_sequence(self, documents):  # documents será un diccionario, donde la clave es el nombre del documento y el valor el texto tokenizado\n",
        "\n",
        "        word_sequence = []\n",
        "        for doc in documents:                     # para cada uno de los documenots\n",
        "            seq = []\n",
        "            for word in doc:\n",
        "                index = self.word_index.get(word)    # obtiene la posición de la palabra en el diccionario creado\n",
        "                if index is not None:                 # solo si el token pertenece al diccionario\n",
        "                    if self.voc_length and index >= self.voc_length: # si la palabra se encuentra más allá del alcance definido del diccionario\n",
        "                        continue\n",
        "                    else:\n",
        "                        seq.append(index)         # se añade la palabra a la lista\n",
        "\n",
        "            word_sequence.append(seq)\n",
        "\n",
        "        return word_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgy4bNASDD4_",
        "colab_type": "text"
      },
      "source": [
        "Función para tokenizar los documentos y las etiquetas (terminología)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcpgR19MDG40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(documents, terminology = False):\n",
        "    tokenized_text = {}\n",
        "    for doc, text in documents.items():\n",
        "        if terminology == False:\n",
        "            tokenized_text[doc] = nltk.word_tokenize(text.lower()) \n",
        "        else:\n",
        "            for term in text:\n",
        "                if doc not in tokenized_text:\n",
        "                    tokenized_text[doc] = [nltk.word_tokenize(term.lower())] \n",
        "                else:\n",
        "                    tokenized_text[doc].append(nltk.word_tokenize(term.lower())) \n",
        "\n",
        "    return tokenized_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOxMoW94xfwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminando puntuación y stopwords\n",
        "def tokenize_text_clean(documents):\n",
        "    nltk.download('stopwords')\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokenized_text = {}\n",
        "    for doc, text in documents.items():\n",
        "        sentence_tok = tokenizer.tokenize(text.lower())\n",
        "\n",
        "        sentence_tok_noSW = []\n",
        "        for token in sentence_tok:\n",
        "            if token not in set(stopwords.words('english')):\n",
        "                sentence_tok_noSW.append(token)\n",
        "                \n",
        "        tokenized_text[doc] = sentence_tok_noSW\n",
        "\n",
        "    return tokenized_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSO4JhmH67l",
        "colab_type": "text"
      },
      "source": [
        "Función para modificar las salidas del modelo en forma clasificatoria: indica con un 0 las palabras que no corresponden a ningún término, 1 si es el inicio de un término, 2 si pertenece a uno.\n",
        "*   Entradas: \n",
        "  * texts: diccionario con el nombre del documento como clave y el texto tokenizado como valor.\n",
        "  * terms: diccionario con el nombre del documento como clave y la terminología tokenizada como valor.\n",
        "*   Salida: \n",
        "  * seq_terms: diccionario con el nombre del documento como clave. El valor indica la clase de cada una de las palabras del documento (0, 1 ó 2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvRI6ZrJJyrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_sequential(texts, terms):              # las entradas son diccionarios\n",
        "\n",
        "    seq_terms = {}\n",
        "\n",
        "    for key, text in texts.items():                    # bucle por documentos\n",
        "        current_terminology = terms[key]               # doc_answers_set: lista con las respuestas del documento actual\n",
        "        current_terminology.sort(key=lambda a: len(a)) # ordena por longitud de los términos. 1º se procesan los más cortos, de manera que si están contenidos en uno más largo, se quedama con el largo\n",
        "        current_term_seq = [0] * len(text)              # secuencia con las clases de todas las palabras del documento, se inicializa como una lista todo a 0s (nada es KP)\n",
        "\n",
        "        for term in current_terminology:             # bucle por palabras pertenecientes a términos\n",
        "            appearances = [i for i, word in enumerate(text) if word == term[0]] # encuentra dónde aparecen las primeras palabras correspondientes a un término (answer[0])\n",
        "            for idx in appearances:                   # bucle de los índices correspondientes a inicios de términos\n",
        "                is_kp = True                          # determina que se encuentra dentro de un término \n",
        "                for i in range(1, len(term)):       # bucle de los índices de respuestas etiquetadas\n",
        "                    if (i + idx) < len(text):\n",
        "                        is_kp = term[i] == text[i + idx]  # comprueba si el término coincide con las siguientes palabras\n",
        "                    else:                             # se ha alcanzado el final del documento, por lo que acaba el término\n",
        "                        is_kp = False               \n",
        "\n",
        "                if is_kp:                             # cuando se ha encontrado un término\n",
        "                    current_term_seq[idx] = 1          # se determina la primera palabra con la clase 1\n",
        "                    for i in range(1, len(term)):\n",
        "                        current_term_seq[idx + i] = 2  # el resto de palabras pertenecientes se identifican con la clase 2\n",
        "\n",
        "        seq_terms[key] = current_term_seq            # se guarda la lista con las clases de los tokens de cada documento en un diccionario\n",
        "\n",
        "    return seq_terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9p231xBYTx1",
        "colab_type": "text"
      },
      "source": [
        "Transforma una lista bidimensional en un vector tridimensional.\n",
        "\n",
        "\n",
        "*   Entrada: vector numpy 2D (nº docs x max_document_length). Representa todas las palabras de los documentos etiquetadas según su clase (0, 1 ó 2).\n",
        "*   Salida: vector numpy 3D (nº docs x max_document_length x nº clases). Representa todas las palabras de los documentos etiquetadas según su clase, mediante un vector se indica la clase correspondiente. Ej clase 0: [1 0 0] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lojpvQHeYUbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_categorical(labels):\n",
        "    num_classes = 3\n",
        "    new_labels = np.zeros((len(labels), len(labels[0]), num_classes))        # prepara el vector para la forma tridimensional\n",
        "    i = 0\n",
        "    for doc in labels:\n",
        "        new_doc = utils.to_categorical(doc, num_classes = num_classes)       # transforma a la forma categórica\n",
        "        new_labels[i] = new_doc\n",
        "        i += 1\n",
        "\n",
        "    return new_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k12IR38zJOUA",
        "colab_type": "text"
      },
      "source": [
        "Función para el preproceso del corpus. Prepara el dataset como entrada de un modelo secuencial y de clasificación.\n",
        "*   Entradas: \n",
        "  * train_text_tok, test_doc, val_doc: diccionario con el nombre del documento como clave, el texto tokenizado como valor.\n",
        "    * train_answer, test_answer, val_answer: diccionario con el nombre del documento como clave, los términos tokenizados como valor.\n",
        "*   Salidas: \n",
        "    * train_x, test_x, val_x: vectores numpy 2D (nº docs x max_document_length). Representa cada palabra con un entero.\n",
        "    * train_y, test_y, val_y: vectores numpy 3D (nº docs x max_document_length x nº clases). Representa la clase de cada una de las palabras de los documentos.\n",
        "    * embedding_matrix: vector numpy 2D (nº palabras del diccionario x long word embeddings)\n",
        "    * vocabulary: objeto Vocabulary con el vocabulario específico de los documentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEe0_K9aIBTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(train_text, train_term, test_text, test_term, val_text, val_term,\n",
        "                       max_sequence_size = 550,\n",
        "                       max_vocabulary_size = 50000, # tamaño máximo del diccionario que se crea con el vocabulario de todos los documentos\n",
        "                       embeddings_size = 300):\n",
        "    # Transformar las respuestas (terminología) en etiquetas de las clases (0: no KP, 1: inicio KP, 2: pertenece a KP)\n",
        "    train_term_seq = to_sequential(train_text, train_term)\n",
        "    test_term_seq = to_sequential(test_text, test_term)\n",
        "    val_term_seq = to_sequential(val_text, val_term)\n",
        "\n",
        "    # Prepara los datos de validación que se devolverán\n",
        "    val_x = None\n",
        "    val_y = None\n",
        "\n",
        "    # Transforma los documentos a secuencias\n",
        "    vocabulary_texts = [] # almacena el vocabulario de todos los documentos\n",
        "    train_y = []          # almacena las etiquetas de las clases\n",
        "    test_y = []\n",
        "    val_y = []\n",
        "\n",
        "    for key, doc in train_text.items():\n",
        "        vocabulary_texts.append(token for token in doc)\n",
        "        train_y.append(train_term_seq[key])\n",
        "    for key, doc in test_text.items():\n",
        "        vocabulary_texts.append(token for token in doc)\n",
        "        test_y.append(test_term_seq[key])\n",
        "    for key, doc in val_text.items():\n",
        "        vocabulary_texts.append(token for token in doc)\n",
        "        val_y.append(val_term_seq[key])\n",
        "\n",
        "    vocabulary = Vocabulary(voc_length = max_vocabulary_size)\n",
        "    vocabulary.new_vocabulary(vocabulary_texts) # crea un diccionario con el vocabulario de todos los textos (entrenamiento, test y validación)\n",
        "\n",
        "    # Prepara las entradas del modelo en base al diccionario creado con el vocabulario. Transforma el texto (tokens) en secuencias\n",
        "    train_x = vocabulary.texts_to_word_sequence(train_text.values())\n",
        "    test_x = vocabulary.texts_to_word_sequence(test_text.values())\n",
        "    val_x = vocabulary.texts_to_word_sequence(val_text.values())\n",
        "\n",
        "    # pad_sequences transforma  una lista de secuencias en un vector 2D\n",
        "    # Now we map the sentences to a sequence of numbers and then pad the sequence. \n",
        "    # Note that we increased the index of the words by one to use zero as a padding value. \n",
        "    # This is done because we want to use the mask_zero parameter of the embedding layer to ignore inputs with value zero.\n",
        "\n",
        "    train_x = np.asarray(pad_sequences(train_x, maxlen=max_sequence_size, padding='post', truncating='post'))\n",
        "    train_y = pad_sequences(train_y, maxlen=max_sequence_size, padding='post', truncating='post')\n",
        "    train_y = to_categorical(train_y)\n",
        "\n",
        "    test_x = np.asarray(pad_sequences(test_x, maxlen=max_sequence_size, padding='post', truncating='post'))\n",
        "    test_y = pad_sequences(test_y, maxlen=max_sequence_size, padding='post', truncating='post')\n",
        "    test_y = to_categorical(test_y)\n",
        "\n",
        "    val_x = np.asarray(pad_sequences(val_x, maxlen=max_sequence_size, padding='post', truncating='post'))\n",
        "    val_y = pad_sequences(val_y, maxlen=max_sequence_size, padding='post', truncating='post')\n",
        "    val_y = to_categorical(val_y)\n",
        "\n",
        "    # Prepara la matriz de entrada de la \"embedding layer\"\n",
        "    word_index = vocabulary.word_index  # diccionario con el vocabulario\n",
        "    embeddings_index = {}               # diccionario con los valores de los word embeddings. Clave: palabra. Valor: coeficiente de los word embeddings.\n",
        "\n",
        "    f = open(EMBEDDING_PATH)\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "\n",
        "    voc_length = min(max_vocabulary_size, 1 + len(word_index))  # el nº de palabras del vocabulario será el tamaño del diccionario creado, si no sobrepasa el máximo. \n",
        "    embedding_matrix = np.zeros((voc_length, embeddings_size))  # matriz filas (palabras del vocabulario) y columnas (tamaño de los word embeddings)\n",
        "    for word, i in word_index.items():\n",
        "        if i >= voc_length:  # si sobrepasa el tamaño del vocabulario\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word) # devuelve el valor del diccionario (coef) dada la clave (palabra)\n",
        "        if embedding_vector is not None:              # las palabras que no estén en los word embeddings serán 0s\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, val_x, val_y, embedding_matrix, vocabulary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flnlB1pcM-Bf",
        "colab_type": "text"
      },
      "source": [
        "Función para el preproceso del corpus, en el caso de que solo se tenga entrada. Se empleará, por tanto, a la hora de predecir la terminología de un texto sin etiquetar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PilM-Hw0pFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_predict_corpus(documents, vocabulary, max_sequence_size = 550): \n",
        "\n",
        "    x = vocabulary.texts_to_word_sequence(documents.values())\n",
        "    x = np.asarray(pad_sequences(x, maxlen = max_sequence_size, padding='post', truncating='post'))  \n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K3LBnjs21BJ",
        "colab_type": "text"
      },
      "source": [
        "Clase para generar callbacks que aporten información de la precisión, el recall y la métrica f1 durante las distintas épocas del entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7bpChG03AGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Metric_Callback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self,val_x,val_y):\n",
        "        self.val_x = val_x\n",
        "        self.val_y = val_y\n",
        "        self.epoch = []\n",
        "        self.history = {}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        y_pred = self.model.predict(self.val_x)\n",
        "        precision_ = precision(self.val_y,y_pred)\n",
        "        recall_ = recall(self.val_y, y_pred)\n",
        "        f1_ = f1(self.val_y, y_pred)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Métricas de validación:\") \n",
        "        print(\"Épcoa     : {}\".format(epoch+1))\n",
        "        print(\"Precisión : {}\".format(precision_))\n",
        "        print(\"Recall    : {}\".format(recall_))\n",
        "        print(\"F1        : {}\".format(f1_))\n",
        "\n",
        "        self.epoch.append(epoch+1)\n",
        "        self.history.setdefault(\"precision\", []).append(precision_)\n",
        "        self.history.setdefault(\"recall\", []).append(recall_)\n",
        "        self.history.setdefault(\"f1\", []).append(f1_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvF4VSR7_AFJ",
        "colab_type": "text"
      },
      "source": [
        "## **Post-procesado**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3wNrM3PAL__",
        "colab_type": "text"
      },
      "source": [
        "Obtención de las palabras que el modelo selecciona como KP (categorías 1 ó 2). Devuelve un diccionario donde la clave es el documento y el valor es una lista con las KP de dicho documento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yH-hBzCGt_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain_words(docs, category_prediction):\n",
        "\n",
        "    doc_count = 0 \n",
        "    obtained_words = {}\n",
        "    for doc, words in docs.items():\n",
        "        token_count = 0  \n",
        "        obtained_words_doc = []   # lista con las palabras obtenidas de cada documentos\n",
        "        in_word = False           # para asegurar que el primer token que selecciona como KP sea inicio (1)\n",
        "        for token in category_prediction[doc_count]:\n",
        "            if token == 1 and token_count < len(words):\n",
        "                obtained_words_doc.append([words[token_count]])\n",
        "                in_word = True    # después de encontrar un inicio (1), ya puede aparecer un 2\n",
        "            elif token == 2 and token_count < len(words) and in_word:\n",
        "                obtained_words_doc[len(obtained_words_doc) - 1].append(words[token_count])\n",
        "            else:\n",
        "                in_word = False\n",
        "            token_count += 1\n",
        "\n",
        "        # Eliminar duplicados \n",
        "        obtained_words_doc.sort()\n",
        "        obtained_words_doc = list(w for w, _ in itertools.groupby(obtained_words_doc))\n",
        "        obtained_words[doc] = obtained_words_doc\n",
        "        doc_count += 1\n",
        "\n",
        "    return obtained_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao4Z0X62Yj1V",
        "colab_type": "text"
      },
      "source": [
        "Función para generar un DataFrame y un fichero csv con la terminología, el documento asociado a cada término y su frecuencia en dicho documento.\n",
        "\n",
        "Entradas: \n",
        "* obtained_words: diccionario con el nombre de los documentos como clave, la terminología asociada como valor.\n",
        "* corpus_path: ruta donde se encuentran los documentos del corpus sobre el que se ha extraído la terminología.\n",
        "* save_term_path: ruta donde se quiere guardar el fichero csv con el DataFrame.\n",
        "\n",
        "Salida: DataFrame generado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVmVyYKYYurC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_df_file(obtained_words, corpus_path, save_term_path, clean_terminology = True):\n",
        "    df = pd.DataFrame(columns=['keyword', 'doc_id', 'Frecuencia'])\n",
        "\n",
        "    index = 0\n",
        "    for doc in obtained_words:   # bucle por cada documento\n",
        "\n",
        "        doc_name = doc + '.abstr'\n",
        "        path = corpus_path + '/' + doc_name\n",
        "        with open(path) as file:\n",
        "            text = file.read().lower()    # se guarda el contenido del documento\n",
        "            text = text.replace('\\n', '')\n",
        "            text = text.replace('\\t', ' ')\n",
        "\n",
        "        for term in obtained_words[doc]: # bucle por cada término (dentro de cada documento)\n",
        "            term_str = ' '.join(term)\n",
        "\n",
        "            if clean_terminology:\n",
        "                sw = stopwords.words('english')\n",
        "                term_list = re.findall(\"([a-z0-9/']+)\", term_str, re.I) # para seleccionar únicamente letras y números\n",
        "                term_str = ' '.join(term_list)\n",
        "                if len(term_str) < 2 or term_str in sw:   # si un término solo tiene menos de 2 caracteres o es una sw, no se almacena\n",
        "                    continue \n",
        "\n",
        "            freq = text.count(term_str)           # se cuenta la frecuencia de los términos\n",
        "            \n",
        "            df.loc[index] = [term_str, doc, freq] \n",
        "            index += 1\n",
        "\n",
        "    df.to_csv(save_term_path, index=False) # se guarda el fichero\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwqGKy8qha6K",
        "colab_type": "text"
      },
      "source": [
        "Para el corpus de Airbus y del COVID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja5doemzRWPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_df_file_corpus(obtained_words, corpus, save_term_path):\n",
        "    df = pd.DataFrame(columns=['keyword', 'doc_id', 'Frecuencia'])\n",
        "    sw = stopwords.words('english')\n",
        "\n",
        "    index = 0\n",
        "    for doc in obtained_words:   # bucle por cada documento\n",
        "\n",
        "        text = corpus[doc]\n",
        "        text = text.replace('\\n', '')\n",
        "        text = text.replace('\\t', ' ')\n",
        "\n",
        "        for term in obtained_words[doc]: # bucle por cada término (dentro de cada documento)\n",
        "            term_str = ' '.join(term)\n",
        "            term_list = re.findall(\"([a-z0-9/']+)\", term_str, re.I) # para seleccionar únicamente letras y números\n",
        "            term_str = ' '.join(term_list)\n",
        "\n",
        "            if len(term_str) < 2 or term_str in sw: # filtrar los términos vacíos, con 1 sola letra o que únicamente es una stopword\n",
        "                continue\n",
        "\n",
        "            freq = text.count(term_str)           # se cuenta la frecuencia de los términos\n",
        "            \n",
        "            df.loc[index] = [term_str, doc, freq] \n",
        "            index += 1\n",
        "\n",
        "    df.to_csv(save_term_path, index=False) # se guarda el fichero\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gP4atTi_N4w",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy9S8kC0q2dp",
        "colab_type": "text"
      },
      "source": [
        "Funciones para obtener la precisión, el recall y la métrica f1 de las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFpcnTxu9Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true_in, y_pred_in) :\n",
        "\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "\n",
        "    # Reducir la dimensión (de 3D a 2D)\n",
        "    y_true = np.argmax(y_true_in, axis=2)\n",
        "    y_pred = np.argmax(y_pred_in, axis=2)\n",
        "\n",
        "    y_true_index = {}\n",
        "    for i in range(np.shape(y_true)[0]):\n",
        "        doc_true_index = []\n",
        "        in_word = False\n",
        "        for j in range(np.shape(y_true)[1]):\n",
        "            if y_true[i][j] == 1 :\n",
        "                doc_true_index.append([\"%s\" % j])\n",
        "                in_word = True\n",
        "            elif j > 0 and y_true[i][j] == 2 and in_word:\n",
        "                doc_true_index[len(doc_true_index) -1].append(\",%s\" % j)\n",
        "            else:\n",
        "                in_word = False\n",
        "\n",
        "        y_true_index[i] = doc_true_index\n",
        "\n",
        "    y_pred_index = {}\n",
        "    for i in range(np.shape(y_pred)[0]):\n",
        "        doc_true_index = []\n",
        "        in_word = False\n",
        "        for j in range(np.shape(y_pred)[1]):\n",
        "            if y_pred[i][j] == 1:\n",
        "                doc_true_index.append([\"%s\" % j])\n",
        "                in_word = True\n",
        "            elif j > 0 and y_pred[i][j] == 2 and in_word:\n",
        "                doc_true_index[len(doc_true_index) - 1].append(\",%s\" % j)\n",
        "            else :\n",
        "                in_word = False\n",
        "\n",
        "        y_pred_index[i] = doc_true_index\n",
        "\n",
        "    for i in range(len(y_pred_index)) :\n",
        "        for kp in y_pred_index[i]:\n",
        "            if kp in y_true_index[i]:\n",
        "                true_positives += 1\n",
        "            else :\n",
        "                false_positives += 1\n",
        "\n",
        "    if true_positives + false_positives > 0:\n",
        "        precision = (true_positives * 1.0) / (true_positives + false_positives)\n",
        "    else: precision = 0\n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4N_ID3P31qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true_in, y_pred_in) :\n",
        "\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "\n",
        "    # Para reducir la dimensión (pasa de 3D a 2D)\n",
        "    y_true = np.argmax(y_true_in, axis=2)\n",
        "    y_pred = np.argmax(y_pred_in, axis=2)\n",
        "\n",
        "    y_true_index = {}\n",
        "\n",
        "    for i in range(np.shape(y_true)[0]):\n",
        "        doc_true_index = []\n",
        "        in_word = False\n",
        "\n",
        "        for j in range(np.shape(y_true)[1]):\n",
        "            if y_true[i][j] == 1 :\n",
        "                doc_true_index.append([\"%s\" % j])\n",
        "                in_word = True\n",
        "            elif j > 0 and y_true[i][j] == 2 and in_word:\n",
        "                doc_true_index[len(doc_true_index) -1].append(\",%s\" % j)\n",
        "            else:\n",
        "                in_word = False\n",
        "\n",
        "        y_true_index[i] = doc_true_index\n",
        "\n",
        "    y_pred_index = {}\n",
        "\n",
        "    for i in range(np.shape(y_pred)[0]):\n",
        "        doc_true_index = []\n",
        "        in_word = False\n",
        "        for j in range(np.shape(y_pred)[1]):\n",
        "\n",
        "            if y_pred[i][j] == 1:\n",
        "                doc_true_index.append([\"%s\" % j])\n",
        "                in_word = True\n",
        "            elif j > 0 and y_pred[i][j] == 2 and in_word:\n",
        "                doc_true_index[len(doc_true_index) - 1].append(\",%s\" % j)\n",
        "            else :\n",
        "                in_word = False\n",
        "\n",
        "        y_pred_index[i] = doc_true_index\n",
        "\n",
        "    for i in range(len(y_pred_index)) :\n",
        "        for kp in y_pred_index[i]:\n",
        "            if kp in y_true_index[i]:\n",
        "                true_positives += 1\n",
        "\n",
        "    return (1.0 * true_positives) / sum(len(kps) for doc,kps in y_true_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1Tl3XDvEGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "\n",
        "    precisionx = precision(y_true, y_pred)\n",
        "    recallx = recall(y_true, y_pred)\n",
        "    if precisionx != 0 and recallx != 0:\n",
        "      f1_score = (2 * (precisionx * recallx)) / (precisionx + recallx)\n",
        "    else: f1_score = 0\n",
        "    return  f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI7zGCBa_ZD3",
        "colab_type": "text"
      },
      "source": [
        "# Pre-proceso. Preparación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b53MsjhxGetS",
        "colab_type": "text"
      },
      "source": [
        "Estructuración del corpus en distintos diccionarios, distinguiendo entre entrenamiento, test y validación, así como los textos y sus salidas deseadas (la terminología)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ogYVc8B1IRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6a862fc1-d5b5-4114-9043-5d3c36ec78ea"
      },
      "source": [
        "! git clone https://githubusercontent.com/luciaguasp/DL-terminology-extraction/tree/master/Datasets/INSPEC/val"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'val'...\n",
            "fatal: unable to access 'https://githubusercontent.com/luciaguasp/DL-terminology-extraction/tree/master/Datasets/INSPEC/val/': Could not resolve host: githubusercontent.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arHTenD0jjfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    train_text, train_term = load_dataset(\"{}/train\".format(DATASET_PATH))\n",
        "    test_text, test_term = load_dataset(\"{}/test\".format(DATASET_PATH))\n",
        "    val_text, val_term = load_dataset(\"{}/val\".format(DATASET_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_HPQw5OGtvx",
        "colab_type": "text"
      },
      "source": [
        "Tokenización de los diccionarios sobre los documentos obtenidos en el paso anterior,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuegWAzI5v25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:  \n",
        "    train_text_tok = tokenize(train_text)\n",
        "    train_term_tok = tokenize(train_term, terminology = True)\n",
        "\n",
        "    test_text_tok = tokenize(test_text)\n",
        "    test_term_tok = tokenize(test_term, terminology = True)\n",
        "\n",
        "    val_text_tok = tokenize(val_text)\n",
        "    val_term_tok = tokenize(val_term, terminology = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQxMnPmv_orC",
        "colab_type": "text"
      },
      "source": [
        "Preparación de las entradas para el modelo secuencial con word embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UVUhVvRRaQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "31bb1aa8-1848-4e22-e476-4aa535eb5787"
      },
      "source": [
        "if only_predict == False: \n",
        "    train_x, train_y, test_x, test_y, val_x, val_y, embedding_matrix, vocabulary_trained = preprocessing(\n",
        "                          train_text_tok, train_term_tok, test_text_tok, test_term_tok, val_text_tok, val_term_tok,\n",
        "                          max_sequence_size = MAX_SEQUENCE_SIZE,\n",
        "                          max_vocabulary_size = MAX_VOCABULARY_SIZE,\n",
        "                          embeddings_size = EMBEDDINGS_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set samples size   :  (1000, 550)\n",
            "Training set answers size   :  (1000, 550, 3)\n",
            "Test set samples size       :  (500, 550)\n",
            "Test set answers size       :  (500, 550, 3)\n",
            "Validation set samples size :  (500, 550)\n",
            "Validation set answers size :  (500, 550, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocBD0rW0A6Is",
        "colab_type": "text"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z70GeIJyHMHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R881eeVxaOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:     \n",
        "    # da mayor peso a las clases que no son 0, es decir, a las palabras pertenecientes a KP\n",
        "    train_y_weights = np.argmax(train_y, axis=2) # devuelve los índices de los valores máximos en el eje 2 \n",
        "    train_y_weights = np.reshape(class_weight.compute_sample_weight('balanced', train_y_weights.flatten()), np.shape(train_y_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Id54as_RkSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:     \n",
        "    model = Sequential()\n",
        "    embedding_layer = Embedding(np.shape(embedding_matrix)[0],        # input_dim = 11261, tamaño del vocabulario\n",
        "                                    EMBEDDINGS_SIZE,                  # output_dim, tamaño de los word embeddings\n",
        "                                    weights = [embedding_matrix],     # concatenación de la lista de pesos\n",
        "                                    input_length = MAX_SEQUENCE_SIZE, # tamaño de las secuencias de entrada\n",
        "                                    trainable = False)                # no se entrenan con mi corpus, sino que se usan los de GloVE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSh0xEpY6s0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False: \n",
        "    if improved_model:\n",
        "        model.add(embedding_layer)\n",
        "        model.add(Bidirectional(LSTM(200, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Bidirectional(LSTM(200, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(TimeDistributed(Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(TimeDistributed(Dense(3, activation='softmax'))) # softmax, clasificación multiclase, con 3 clases (salidas)\n",
        "    else:        \n",
        "        model.add(embedding_layer)\n",
        "        model.add(Bidirectional(LSTM(300, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(TimeDistributed(Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(TimeDistributed(Dense(3, activation='softmax'))) # softmax, clasificación multiclase, con 3 clases (salidas)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'],\n",
        "                      sample_weight_mode=\"temporal\")\n",
        "    # model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'],\n",
        "    #                 sample_weight_mode=\"temporal\")\n",
        "    print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyjeKHWuTKQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:     \n",
        "    metrics_callback = Metric_Callback(val_x, val_y)\n",
        "    \n",
        "    history = model.fit(train_x, train_y,\n",
        "                            validation_data=(val_x, val_y),\n",
        "                            epochs=EPOCHS,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            sample_weight=train_y_weights, \n",
        "                            callbacks=[metrics_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgC435OgT8ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:     \n",
        "    models.save_model(model, MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrsKGJl_bxq3",
        "colab_type": "text"
      },
      "source": [
        "Se muestra la gráfica del accuracy en función de la epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsFE9uJ6b8O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:   \n",
        "    f = plt.figure()    \n",
        "    plt.xlim(0, 29)\n",
        "    plt.plot(history.history['accuracy'], color = 'steelblue')\n",
        "    plt.plot(history.history['val_accuracy'], color = 'lightcoral')\n",
        "    plt.title('Precisión del modelo')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(['Entrenamiento', 'Validación'], loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbKBlZ5XN8fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:     \n",
        "    f = plt.figure()  \n",
        "    plt.ylim(0, 1)\n",
        "    plt.xlim(0, 29)\n",
        "\n",
        "    plt.plot(history.history['accuracy'], color = 'steelblue')\n",
        "    plt.plot(history.history['val_accuracy'], color = 'lightcoral')\n",
        "    plt.title('Precisión del modelo')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(['Entrenamiento', 'Validación'], loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buqZI8cDb_l5",
        "colab_type": "text"
      },
      "source": [
        "Gráfica de la función de coste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU-pNFrRcBpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if new_model == True and only_predict == False:  \n",
        "    f = plt.figure()   \n",
        "    plt.xlim(0, 29)\n",
        "    plt.plot(history.history['loss'], color = 'steelblue')\n",
        "    plt.plot(history.history['val_loss'], color = 'lightcoral')\n",
        "    plt.title('Función de coste del modelo')\n",
        "    plt.ylabel('Coste')\n",
        "    plt.xlabel('Época')\n",
        "    plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1B_extB9b9n",
        "colab_type": "text"
      },
      "source": [
        "# Evaluación test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNfGKMWp-JPG",
        "colab_type": "text"
      },
      "source": [
        "Se carga el modelo y se predicen los resultados con el corpus de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B151fUdxeCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    model = models.load_model(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNS92LlKKCyR",
        "colab_type": "text"
      },
      "source": [
        "El vector que se obtiene con la predicción (output_test) selecciona los 400 tokens de cada uno de los 100 documentos en las 3 categorías posibles. Obtiene la probabilidad de pertenecer a cada una de las categorías."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4Z_khb-HLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    output_test = model.predict(x=test_x, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKNV5I4VKct2",
        "colab_type": "text"
      },
      "source": [
        "Se transforma el vector en 3D obtenido por otro en 2D que indique la categoría de cada uno de los 400 tokens de los 100 documentos. En cada token, nos quedamos con la categoría que tiene una mayor probabilidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsprOzD-J7ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    obtained_tokens_test = np.argmax(output_test,axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZYRH0EPGtXB",
        "colab_type": "text"
      },
      "source": [
        "Obtención de las palabras indicadas como KP (1 ó 2). Se obtiene un diccionario donde la clave es el documento y el valor es la lista con las KP de dicho documento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjCCu8Y-gJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    obtained_words_test = obtain_words(test_text_tok, obtained_tokens_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCpFNqfdyDkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if only_predict == False:\n",
        "    test_precision = precision(test_y, output_test)\n",
        "    test_recall = recall(test_y, output_test)\n",
        "    test_f1 = f1(test_y, output_test)\n",
        "    print(\"MÉTRICAS SOBRE TEST \\nPrecisión: {}\\nRecall: {}\\nf1: {}\".format(test_precision, test_recall, test_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc0OCc0Kze_I",
        "colab_type": "text"
      },
      "source": [
        "# Generar fichero csv con la terminología test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPb6Ufk91TvD",
        "colab_type": "text"
      },
      "source": [
        "Se genera el DataFrame y el fichero csv en el que se encuentra la terminología, el documento del que procede y la frecuencia en dicho documento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkJXWnuWmUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if save_term_test:    \n",
        "    inspec_test_path = DATASET_PATH + '/test'\n",
        "    df_test = create_df_file(obtained_words_test, inspec_test_path, TERM_PATH_INSPEC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-BTH_uiBHDX",
        "colab_type": "text"
      },
      "source": [
        "# Predicción sobre el corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCpIvuiPBpA8",
        "colab_type": "text"
      },
      "source": [
        "Se carga el modelo ya entrenado y el corpus del que se quiere extraer la terminología y se pre-procesa para que cuadre con el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO3k2beG93sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:   \n",
        "    model = models.load_model(MODEL_PATH)\n",
        "    corpus_pickle = open(CORPUS_PATH,'rb')\n",
        "    corpus = pickle.load(corpus_pickle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61gLdtYFYaaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    corpus_text_tok = tokenize_text_clean(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ9Je4ShYgNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:  \n",
        "    vocabulary_trained = pickle.load(open(VOCABULARY_PATH,'rb'))\n",
        "    corpus_x = preprocessing_predict_corpus(corpus_text_tok, vocabulary_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6WDEnpMTTXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    output = model.predict(corpus_x, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVe9BsYJB6d3",
        "colab_type": "text"
      },
      "source": [
        "A partir de la salida obtenida, se transforma el vector tridimensional (documentos, token, categoría) en un vector bidimensional (documentos, token_categoría)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St6bA1mmBoKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    obtained_tokens = np.argmax(output,axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azyqnf34grVL",
        "colab_type": "text"
      },
      "source": [
        "Se extraen las palabras que representan. Se obtiene un diccionario donde las claves son los nombres de los documentos y los valores son los términos seleccionados. Estos términos están sepresentados mediante listas formadas por cada token. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ZLXBPJJqUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    obtained_words = obtain_words(corpus_text_tok, obtained_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oT00dZFvfGX9"
      },
      "source": [
        "Se genera el DataFrame y el fichero csv en el que se encuentra la terminología, el documento del que procede y la frecuencia en dicho documento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lxVIUfaSsLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    df_corpus = create_df_file_corpus(obtained_words, corpus, TERM_PATH_CORPUS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNFK7_gLcpp6",
        "colab_type": "text"
      },
      "source": [
        "Filtrar los términos con frecuencia 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArQ9Gfc_mHHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if predict:    \n",
        "    df_corpus = df_corpus.drop(df_corpus[df_corpus.Frecuencia == 0].index)\n",
        "    df_corpus.to_csv(TERM_PATH_CORPUS, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}